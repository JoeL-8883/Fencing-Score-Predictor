{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from io import StringIO\n",
    "import gdown\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert event abbreviation to full text for readability\n",
    "def get_event_type(event):\n",
    "    event = event.strip('()').upper()\n",
    "\n",
    "    EVENT_TYPES = {\n",
    "        'GP': 'Grand Prix',\n",
    "        'JO': 'Olympics',\n",
    "        'SA': 'Satellite',\n",
    "        'A': 'World Cup',\n",
    "        'CHZ': 'Zonal Championship',\n",
    "        'CHM': 'World Championship'\n",
    "    }\n",
    "\n",
    "    if event in EVENT_TYPES:\n",
    "        return EVENT_TYPES[event]\n",
    "    else:\n",
    "        raise ValueError(f'Unknown event type: {event}')\n",
    "    \n",
    "# Get date, event host city and type of event\n",
    "def get_tournament_data(tournament_data):\n",
    "    tournament_split = tournament_data.split()\n",
    "    date = tournament_split[0]\n",
    "    host_city = ' '.join(tournament_split[1:-1])\n",
    "    event_type = get_event_type(tournament_split[-1])\n",
    "\n",
    "    return date, host_city, event_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate through each data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Iterate through a list of CSVs containing results of each fencer '''\n",
    "current_dir = os.getcwd()\n",
    "results_dir = os.path.join(current_dir, 'results')\n",
    "\n",
    "if not os.listdir(results_dir):\n",
    "    # Download from Google Drive\n",
    "    gdown.download_folder(\n",
    "        url='https://drive.google.com/drive/folders/1rkwkF7DOcJhgIw_KXJSV9w4qJN2rq9GT',\n",
    "        output=results_dir,\n",
    "        quiet=False,\n",
    "        use_cookies=False\n",
    "    )\n",
    "else:\n",
    "    data = []\n",
    "    for results in os.listdir(results_dir):\n",
    "        results_path = os.path.join(results_dir, results)\n",
    "        if results_path.endswith('csv'):\n",
    "            with open(results_path, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "\n",
    "                tournaments = lines[3].strip()\n",
    "                reader = csv.reader(StringIO(tournaments))\n",
    "                tournaments = list(reader)[0][2:-1]\n",
    "\n",
    "                for line in lines[4:504]:\n",
    "                    line = line.strip()\n",
    "                    columns = line.split(',')\n",
    "                    rank = columns[0]\n",
    "                    fencer_name = columns[1]\n",
    "                    nationality = columns[2]\n",
    "                \n",
    "                    for i, tournament in enumerate(tournaments):\n",
    "                        points_index = 3 + i # points start at column 3\n",
    "                        points = columns[points_index]\n",
    "\n",
    "                        if points:\n",
    "                            points = abs(float(points))\n",
    "                            date, host_city, event_type = get_tournament_data(tournament)\n",
    "                            data.append([fencer_name, rank, nationality, host_city, event_type, points, date])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store data to Panda dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fencer_name</th>\n",
       "      <th>rank</th>\n",
       "      <th>nationality</th>\n",
       "      <th>host_city</th>\n",
       "      <th>event_type</th>\n",
       "      <th>points_earned</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MASSIALAS Alexander</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "      <td>Bonn</td>\n",
       "      <td>World Cup</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2022-11-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MASSIALAS Alexander</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>World Cup</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2022-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MASSIALAS Alexander</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "      <td>Paris</td>\n",
       "      <td>World Cup</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2023-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MASSIALAS Alexander</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "      <td>Turin</td>\n",
       "      <td>Grand Prix</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2023-02-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MASSIALAS Alexander</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>World Cup</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2023-02-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           fencer_name rank nationality host_city  event_type  points_earned  \\\n",
       "0  MASSIALAS Alexander    1         USA      Bonn   World Cup            2.0   \n",
       "1  MASSIALAS Alexander    1         USA     Tokyo   World Cup           14.0   \n",
       "2  MASSIALAS Alexander    1         USA     Paris   World Cup           32.0   \n",
       "3  MASSIALAS Alexander    1         USA     Turin  Grand Prix           21.0   \n",
       "4  MASSIALAS Alexander    1         USA     Cairo   World Cup           32.0   \n",
       "\n",
       "        date  \n",
       "0 2022-11-11  \n",
       "1 2022-12-09  \n",
       "2 2023-01-12  \n",
       "3 2023-02-11  \n",
       "4 2023-02-23  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns=['fencer_name', 'rank', 'nationality', 'host_city', 'event_type', 'points_earned', 'date'])\n",
    "df = df.drop_duplicates(subset=['fencer_name', 'host_city', 'date'], keep='last')\n",
    "df['date'] = pd.to_datetime(df['date'], format='%d.%m.%y')\n",
    "df.to_csv('data.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get date of birth and FIE ID data of each fencer using JSONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import fitz\n",
    "import re\n",
    "\n",
    "# Get JSON data of a fencer that includes their FIE ID and date of birth\n",
    "def Get_Fencer_JSON(name):\n",
    "  url = \"https://fie.org/athletes/search\"\n",
    "  payload = {\"name\": name}\n",
    "  \n",
    "  resp = requests.post(url, json=payload, timeout=10)\n",
    "  resp.raise_for_status()\n",
    "  return resp.json()\n",
    "\n",
    "'''This code is actually mostly redundant as the true issue was with retrieving the wrong ID for fencers with the same target name'''\n",
    "def fetch_dob(id, name, fencer_dict):\n",
    "  dob = None\n",
    "  url = f\"https://fie.org/athletes/{id}/profile\"\n",
    "  headers = {\n",
    "      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "  }\n",
    "  resp = requests.get(url, headers=headers, timeout=10)\n",
    "  resp.raise_for_status()\n",
    "\n",
    "  # This code was working, then stopped unknownly\n",
    "  pdf = fitz.open(stream=resp.content, filetype=\"pdf\")\n",
    "  text = \"\"\n",
    "  for page in pdf:\n",
    "    text += page.get_text()\n",
    "  \n",
    "  print(text)\n",
    "  pdf.close()\n",
    "\n",
    "  # Use regex to find the date of birth in the text\n",
    "  pattern = r\"Date of birth:\\s*\\n?\\s*(\\d{4}-\\d{2}-\\d{2})\"\n",
    "  match = re.search(pattern, text)\n",
    "  if match:\n",
    "    dob = match.group(1)\n",
    "    print(f\"DOB found for {name}\")\n",
    "    print()\n",
    "  else:\n",
    "    print(f\"Date of birth not found for {name} {id} {url}\")\n",
    "    print(fencer_dict)\n",
    "    print()\n",
    "  return dob\n",
    "\n",
    "def retry_fetch(name, retries=3):\n",
    "   # Try to fetch data with different variations of the name\n",
    "      variations = [\n",
    "        name.split()[0].capitalize() + ' ' + name.split()[1],\n",
    "        name.split()[0] + ' ' + name.split()[1].lower(),\n",
    "        # Add more variants if needed\n",
    "      ]\n",
    "\n",
    "      for variant in variations:\n",
    "        print(f\"Trying {variant}\")\n",
    "        results = Get_Fencer_JSON(variant)\n",
    "        fencer_dict = list(results.values())[0][0]\n",
    "        id = fencer_dict.get('id')\n",
    "        dob = fencer_dict.get('date')\n",
    "        if id and dob:\n",
    "          print(f\"Fetched data for {variant}\")\n",
    "          return id, dob\n",
    "\n",
    "      # Try retrying with original name\n",
    "      counter = 0\n",
    "      while(not id or not dob) and counter < retries:\n",
    "        time.sleep(2)\n",
    "        counter += 1\n",
    "        results = Get_Fencer_JSON(name)\n",
    "        fencer_dict = list(results.values())[0][0]\n",
    "        id = fencer_dict.get('id')\n",
    "        dob = fencer_dict.get('date')\n",
    "      if not id or not dob:\n",
    "        print(f\"Failed to fetch data for {name} after {retries} attempts\")\n",
    "        print()\n",
    "      else:\n",
    "        print(f\"Fetched data for {name} after {counter} attempts\")\n",
    "        print()\n",
    "      return None, None\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data found for DOST-MUHAMEDOV Rustan after 3 retries\n",
      "Warning - fencer will be removed from the dataset\n",
      "\n",
      "No data found for SRITANG-ORN Suppakorn after 3 retries\n",
      "Warning - fencer will be removed from the dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Note this code takes a long time to run as it fetches data for each fencer individually from the FIE website'''\n",
    "names = df['fencer_name'].unique()\n",
    "df['fie_ID'] = None\n",
    "df['dob'] = None\n",
    "\n",
    "''' Fetch FIE IDs and dates of birth for each fencer '''\n",
    "# There are multiple irrelevant athlete profiles that have the same names of fencers, they often have incomplete JSON data\n",
    "# We can check that we have the correct fencer by checking the level and weapon in the JSON data\n",
    "for name in names:\n",
    "  try:\n",
    "    results = Get_Fencer_JSON(name)\n",
    "    json_data = list(results.values())[0]\n",
    "    if json_data is None or len(json_data) == 0:\n",
    "\n",
    "      # Retry getting data if json is empty\n",
    "      max_retries = 3\n",
    "      for retry in range(max_retries):\n",
    "        try:\n",
    "          results = Get_Fencer_JSON(name)\n",
    "          json_data = list(results.values())[0]\n",
    "          if json_data or len(json_data) > 0:\n",
    "            break\n",
    "        except requests.exceptions.RequestException as e:\n",
    "          time.sleep(2)\n",
    "        time.sleep(2)\n",
    "      if json_data is None or len(json_data) == 0:\n",
    "        print(f\"No data found for {name} after {max_retries} retries\")\n",
    "        print(\"Warning - fencer will be removed from the dataset\\n\")\n",
    "        df = df[df['fencer_name'] != name]\n",
    "        continue\n",
    "      \n",
    "    else:\n",
    "      # Validate that we have the correct fencer\n",
    "      # Note: this assumes that senior male foilist fencers have unique names\n",
    "      for fencer in json_data:\n",
    "        if fencer['level'] == 'S' and fencer['weapon'] == 'F':\n",
    "          fencer_dict = fencer\n",
    "          break\n",
    "      if not fencer_dict:\n",
    "        raise ValueError(f\"Could not find correct data for {name}\")\n",
    "\n",
    "      # Ensure that id and date of birth are present\n",
    "      try:\n",
    "        id = fencer_dict['id']\n",
    "        if not id:\n",
    "          raise ValueError(f\"ID is empty for {name}\")    \n",
    "      except KeyError:\n",
    "          raise KeyError(f\"No id found for {name}\")\n",
    "\n",
    "      try:\n",
    "        dob = fencer_dict['date']\n",
    "        if not dob:\n",
    "          raise ValueError(f\"Date of birth is empty for {name}\")\n",
    "      except KeyError:\n",
    "        raise KeyError(f\"No date of birth found for {name}\")\n",
    "\n",
    "      df.loc[df['fencer_name'] == name, 'fie_ID'] = id\n",
    "      df.loc[df['fencer_name'] == name, 'dob'] = dob\n",
    "\n",
    "  except requests.exceptions.RequestException as e:\n",
    "    raise(f\"Request error for {name}\")\n",
    "  # There are consistent index errors for few fencers and their JSON data seems inconsistent\n",
    "  # So it is fine to just remove them from the dataset as they are not key fencers\n",
    "  except IndexError as e:\n",
    "    print(f\"Index error for {name}: {e}\")\n",
    "    print(fencer_dict)\n",
    "    print(\"Warning - fencer will be removed from the dataset\")\n",
    "    df = df[df['fencer_name'] != name]\n",
    "    print()\n",
    "    continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine ages of fencers at time of competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing fencer SANGOWAWA Babatunde Olufemi due to missing or incorrect date of birth\n"
     ]
    }
   ],
   "source": [
    "'''Verify that all fencers in df have a dob'''\n",
    "df['dob'] = pd.to_datetime(df['dob'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "# Some FIE profiles have an incorrect date of birth format, we just remove these fencers from the dataset\n",
    "# i.e. see https://fie.org/athletes/38249/profile\n",
    "missing_age_rows = df[df['dob'].isna()]\n",
    "missing_fencer_names = missing_age_rows['fencer_name'].unique().tolist()\n",
    "\n",
    "for name in missing_fencer_names:\n",
    "    print(f\"Removing fencer {name} due to missing or incorrect date of birth\")\n",
    "    df = df[df['fencer_name'] != name]\n",
    "\n",
    "df['age'] = ( (df['date'] - df['dob']).dt.days // 365.25).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['nationality', 'rank', 'host_city', 'points_earne'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-120dd7fc6015>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m ]\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_column_order\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/fencing_points/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3766\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3767\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3769\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/fencing_points/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5875\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5877\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5879\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/fencing_points/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5940\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5941\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5943\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['nationality', 'rank', 'host_city', 'points_earne'] not in index\""
     ]
    }
   ],
   "source": [
    "'''Reorganise columns for better readability'''\n",
    "new_column_order = [\n",
    "    'fie_ID', \n",
    "    'fencer_name', \n",
    "    'age', \n",
    "    'dob', \n",
    "    'nationality',  # I assume this is your \"nationality\" column\n",
    "    'rank',        # I assume this is your \"rank\" column\n",
    "    'host_city', \n",
    "    'event_type', \n",
    "    'points_earne', \n",
    "    'date'\n",
    "]\n",
    "\n",
    "df = df[new_column_order]\n",
    "df.to_csv('data.csv', index=False)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fencing_points",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
